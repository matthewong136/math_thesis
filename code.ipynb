{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.decomposition import PCA\n",
    "import prince\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifical = [\"AAACFCCDA\",'ACCDGCDEA','AAAEHCCFA','ACCFICDDA','AAACFCCCA','ACCDGCDFA','AAAEHCCDA','ACCFICDEA','AAACFCCFA','ACCDGCDDA','CDAFCCDAH','CECGDCFGL','CDAHFCDAK','CECFGCFGL','CDAHDCFNM','CECHDCFNG','CDAFFCDAP','CECGGCFGQ','CDAHCDAHR','CECFDCFGS']\n",
    "art_labels = [\"Group 1\",\"Group 1\",\"Group 1\",\"Group 1\",\"Group 1\",\"Group 1\",\"Group 1\",\"Group 1\",\"Group 1\",\"Group 1\",\"Group 2\",\"Group 2\",\"Group 2\",\"Group 2\",\"Group 2\",\"Group 2\",\"Group 2\",\"Group 2\",\"Group 2\",\"Group 2\",]\n",
    "\n",
    "def fasta_input_labeled(fasta,label):\n",
    "    with open(fasta, 'r') as file:\n",
    "        seqs = file.read().split('>')[1:]\n",
    "    labels = []\n",
    "    for i in range(len(seqs)):\n",
    "        if label in seqs[i]:\n",
    "            temp_label = \"Group 1\"\n",
    "        else:\n",
    "            temp_label = \"Group 2\"\n",
    "        seqs[i] = seqs[i][seqs[i].find('\\n')+1:].replace('\\n', '')\n",
    "        labels.append(temp_label)\n",
    "\n",
    "    return pd.DataFrame({'Sequence': seqs, 'Label': labels})\n",
    "\n",
    "art_sequences = pd.DataFrame({'Sequence': artifical, 'Label': art_labels})\n",
    "mamvert_sequences = fasta_input_labeled('mamVert.fas', label = 'Mammals')\n",
    "hexapeptide_sequences = pd.read_csv('hexapeptides_labled.csv')\n",
    "feline_sequences = fasta_input_labeled('feline.txt', label = 'VSD_')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vfactor_conversion = {\n",
    "    'X' : [0,0,0,0,0],\n",
    "    '-' : [0,0,0,0,0],\n",
    "    'A': [-0.591, -1.302, -0.733, 1.570, -0.146],\n",
    "    'C': [-1.343, 0.465, -0.862, -1.020, -0.255],\n",
    "    'D': [1.050, 0.302, -3.656, -0.259, -3.242],\n",
    "    'E': [1.357, -1.453, 1.477, 0.113, -0.837],\n",
    "    'F': [-1.006, -0.590, 1.891, -0.397, 0.412],\n",
    "    'G': [-0.384, 1.652, 1.330, 1.045, 2.064],\n",
    "    'H': [0.336, -0.417, -1.673, -1.474, -0.078],\n",
    "    'I': [-1.239, -0.547, 2.131, 0.393, 0.816],\n",
    "    'K': [1.831, -0.561, 0.533, -0.277, 1.648],\n",
    "    'L': [-1.019, -0.987, -1.505, 1.266, -0.912],\n",
    "    'M': [-0.663, -1.524, 2.219, -1.005, 1.212],\n",
    "    'N': [0.945, 0.828, 1.299, -0.169, 0.933],\n",
    "    'P': [0.189, 2.081, -1.628, 0.421, -1.392],\n",
    "    'Q': [0.931, -0.179, -3.005, -0.503, -1.853],\n",
    "    'R': [1.538, -0.055, 1.502, 0.440, 2.897],\n",
    "    'S': [-0.228, 1.399, -4.760, 0.670, -2.647],\n",
    "    'T': [-0.032, 0.326, 2.213, 0.908, 1.313],\n",
    "    'V': [-1.337, -0.279, -0.544, 1.242, -1.262],\n",
    "    'W': [-0.595, 0.009, 0.672, -2.128, -0.184],\n",
    "    'Y': [0.260, 0.830, 3.097, -0.838, 1.512],\n",
    "}\n",
    "\n",
    "binary_conversion = {\n",
    "    'A': [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    'C': [0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    'D': [0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    'E': [0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    'F': [0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    'G': [0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    'H': [0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    'I': [0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    'K': [0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    'L': [0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0],\n",
    "    'M': [0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0],\n",
    "    'N': [0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0],\n",
    "    'P': [0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0],\n",
    "    'Q': [0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0],\n",
    "    'R': [0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0],\n",
    "    'S': [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0],\n",
    "    'T': [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0],\n",
    "    'V': [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0],\n",
    "    'W': [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0],\n",
    "    'Y': [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],\n",
    "    '-': [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    'X': [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "}\n",
    "\n",
    "IX_conversion = {\n",
    "    'X' : [0,0,0,0,0,0,0,0,0,0],\n",
    "    '-' : [0,0,0,0,0,0,0,0,0,1],\n",
    "    'A':[1,\t0\t,0\t,0,\t0,\t1,\t0,\t0\t,0,\t0],\n",
    "    'C': [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "    'D': [0, 0, 1, 1, 1, 1, 0, 0, 0, 0],\n",
    "    'E': [0, 0, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "    'F': [1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "    'G': [1, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "    'H': [1, 1, 0, 1, 1, 0, 1, 0, 0, 0],\n",
    "    'K': [1, 1, 0, 1, 1, 0, 0, 0, 0, 0],\n",
    "    'I': [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "    'L': [1, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "    'M': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'N': [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
    "    'P': [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
    "    'Q': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    'R': [0, 1, 0, 1, 1, 0, 0, 0, 0, 0],\n",
    "    'S': [0, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
    "    'T': [1, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
    "    'V': [1, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n",
    "    'W': [1, 0, 0, 1, 0, 0, 1, 0, 0, 0],\n",
    "    'Y': [1, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_conv(sequences, labels = pd.DataFrame()):\n",
    "    binary = []\n",
    "    for seq in sequences:\n",
    "        binary_seq = []\n",
    "        for aa in seq:\n",
    "            binary_seq = binary_seq + binary_conversion[aa]\n",
    "        binary.append(binary_seq)\n",
    "    \n",
    "    converted = pd.DataFrame(binary,columns = \n",
    "                             [\"Position \" + \n",
    "                              str(i) for i in range(1,len(binary[1]) + 1)])\n",
    "    if labels.empty == False:\n",
    "        converted[\"Labels\"] = labels\n",
    "    return converted\n",
    "\n",
    "\n",
    "\n",
    "def Vfactor_conv(sequences, labels = pd.DataFrame()):\n",
    "    \n",
    "    Vfactor = []\n",
    "    for seq in sequences:\n",
    "        Vfactor_seq = []\n",
    "        for aa in seq:\n",
    "            Vfactor_seq = Vfactor_seq + Vfactor_conversion[aa]\n",
    "        Vfactor.append(Vfactor_seq)\n",
    "\n",
    "    seq_length = int(len(Vfactor[1])/5)\n",
    "\n",
    "    positions = []\n",
    "    for i in range(1,seq_length + 1):\n",
    "        positions.append(\"Position \" + str(i) + \"I\")\n",
    "        positions.append(\"Position \" + str(i) + \"II\")\n",
    "        positions.append(\"Position \" + str(i) + \"III\")\n",
    "        positions.append(\"Position \" + str(i) + \"IV\")\n",
    "        positions.append(\"Position \" + str(i) + \"V\")\n",
    "\n",
    "    converted = pd.DataFrame(Vfactor,columns = positions)\n",
    "\n",
    "    if labels.empty == False:\n",
    "        converted[\"Labels\"] = labels\n",
    "        return converted\n",
    "    \n",
    "    return converted\n",
    "\n",
    "\n",
    "def IXfactor_conv(sequences, labels = pd.DataFrame()):\n",
    "    IXfactor = []\n",
    "    for seq in sequences:\n",
    "        IXfactor_seq = []\n",
    "        for aa in seq:\n",
    "            IXfactor_seq = IXfactor_seq + IX_conversion[aa]\n",
    "        IXfactor.append(IXfactor_seq)\n",
    "\n",
    "    seq_length = int(len(IXfactor[1])/10)\n",
    "\n",
    "    positions = []\n",
    "    for i in range(1,seq_length + 1):\n",
    "        positions.append(\"Position \" + str(i) + \"I\")\n",
    "        positions.append(\"Position \" + str(i) + \"II\")\n",
    "        positions.append(\"Position \" + str(i) + \"III\")\n",
    "        positions.append(\"Position \" + str(i) + \"IV\")\n",
    "        positions.append(\"Position \" + str(i) + \"V\")\n",
    "        positions.append(\"Position \" + str(i) + \"VI\")\n",
    "        positions.append(\"Position \" + str(i) + \"VII\") \n",
    "        positions.append(\"Position \" + str(i) + \"VIII\")\n",
    "        positions.append(\"Position \" + str(i) + \"IX\")\n",
    "        positions.append(\"Position \" + str(i) + \"X\")\n",
    "    \n",
    "    converted = pd.DataFrame(IXfactor,columns = positions)\n",
    "\n",
    "    if labels.empty == False:\n",
    "        converted[\"Labels\"] = labels\n",
    "        return converted\n",
    "    \n",
    "    return converted\n",
    "\n",
    "\n",
    "\n",
    "def variability_conv(seqs,labels = pd.DataFrame):\n",
    "    var_coded = [[0 \n",
    "                  for i in range(len(seqs[1]))] \n",
    "                  for j in range(len(seqs))]\n",
    "    coder = {}\n",
    "\n",
    "    for position in range(len(seqs[1])):\n",
    "        \n",
    "        #making the dictionary\n",
    "        for protein in range(len(seqs)):\n",
    "            if seqs[protein][position] == '-':\n",
    "                coder[seqs[protein][position]] = 0\n",
    "            elif seqs[protein][position] in coder.keys():\n",
    "                coder[seqs[protein][position]] += 1\n",
    "            else:\n",
    "                coder[seqs[protein][position]] = 1\n",
    "\n",
    "        coder = sorted(coder.items(), key=lambda x:x[1], \n",
    "                       reverse=False)\n",
    "        coder = dict(coder)\n",
    "        \n",
    "        for i, key in enumerate(coder):\n",
    "            coder[key] = i\n",
    "        \n",
    "        #filling in the matrix\n",
    "        for protein in range(len(seqs)):\n",
    "            var_coded[protein][position] = coder.get(\n",
    "                seqs[protein][position])\n",
    "\n",
    "        coder.clear()\n",
    "    \n",
    "    positions = []\n",
    "    for i in range(1,len(var_coded[1]) + 1):\n",
    "        positions.append(\"Position \" + str(i))\n",
    "    \n",
    "    converted = pd.DataFrame(var_coded,columns = positions)\n",
    "\n",
    "    if labels.empty == False:\n",
    "        converted[\"Labels\"] = labels\n",
    "    return converted\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions for PCA and MCA\n",
    "def pca_prince(dataframe ,label1 ,label2, component1 = 1, component2 = 2,remove_outliers = True):\n",
    "    pca = prince.PCA(\n",
    "        n_components= component2,\n",
    "        n_iter=3,\n",
    "        copy=True,\n",
    "        check_input=True,\n",
    "        engine='sklearn',\n",
    "        random_state=47\n",
    "    )\n",
    "\n",
    "    dataframe_unlabeled = dataframe.drop(columns = ['Labels'])\n",
    "\n",
    "    pca = pca.fit(dataframe_unlabeled)\n",
    "    data = pca.row_coordinates(dataframe_unlabeled)\n",
    "\n",
    "    if remove_outliers == True:\n",
    "        upper_PC1 = data.quantile(.95)[component1-1]\n",
    "        lower_PC1 = data.quantile(.05)[component1-1]\n",
    "        upper_PC2 = data.quantile(.95)[component2-1]\n",
    "        lower_PC2 = data.quantile(.05)[component2-1]\n",
    "\n",
    "        outliers = []\n",
    "        for i in range(len(data)):\n",
    "            if data[component1-1][i] > upper_PC1 or data[component1-1][i] < lower_PC1:\n",
    "                outliers.append(i)\n",
    "            elif data[component2-1][i] > upper_PC2 or data[component2-1][i] < lower_PC2:\n",
    "                outliers.append(i)\n",
    "\n",
    "        dataframe_new = dataframe.drop(outliers)\n",
    "        dataframe_new_unlabeled = dataframe_new.drop(columns = ['Labels'])\n",
    "\n",
    "        pca = prince.PCA(\n",
    "        n_components= component2,\n",
    "        n_iter=3,\n",
    "        copy=True,\n",
    "        check_input=True,\n",
    "        engine='sklearn',\n",
    "        random_state=47\n",
    "        )\n",
    "\n",
    "        pca = pca.fit(dataframe_new_unlabeled)\n",
    "        data = pca.row_coordinates(dataframe_new_unlabeled)\n",
    "        \n",
    "        data.insert(component2,\"Group\",dataframe_new[\"Labels\"])\n",
    "    else:\n",
    "        data.insert(component2,\"Group\",dataframe[\"Labels\"])\n",
    "\n",
    "    colors = {label1: '#E66100', label2: '#5D3A9B'}\n",
    "    color_list = [colors[group] for group in data['Group']]\n",
    "\n",
    "    variances = pca.eigenvalues_summary[\"% of variance\"]\n",
    "\n",
    "    data.plot.scatter(x=component1-1,y=component2-1,c=color_list, grid = False,\n",
    "                      xlabel = \"PC\" + str(component1) + \" (\" +variances[component1-1] + \")\",\n",
    "                      ylabel = \"PC\" + str(component2) + \" (\" +variances[component2-1]+ \")\")\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "\n",
    "    #define patches and lines to add to legend\n",
    "    patch1 = mpatches.Patch(color='#E66100', label=\"VSD\")\n",
    "    patch2 = mpatches.Patch(color='#5D3A9B', label=\"ORD\")   \n",
    "    handles.extend([patch1, patch2])\n",
    "    plt.legend(handles=handles)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def mca_prince(dataframe, label1, label2, component1 = 1, component2 = 2,remove_outliers = True):\n",
    "    mca = prince.MCA(\n",
    "        n_components= component1 + component2,\n",
    "        n_iter=3,\n",
    "        copy=True,\n",
    "        check_input=True,\n",
    "        engine='sklearn',\n",
    "        random_state=47\n",
    "    )\n",
    "\n",
    "    dataframe_unlabeled = dataframe.drop(columns = ['Labels'])\n",
    "\n",
    "    mca = mca.fit(dataframe_unlabeled)\n",
    "    data = mca.row_coordinates(dataframe_unlabeled)\n",
    "\n",
    "    if remove_outliers == True:\n",
    "        upper_PC1 = data.quantile(.95)[component1-1]\n",
    "        lower_PC1 = data.quantile(.05)[component1-1]\n",
    "        upper_PC2 = data.quantile(.95)[component2-1]\n",
    "        lower_PC2 = data.quantile(.05)[component2-1]\n",
    "\n",
    "        outliers = []\n",
    "        for i in range(len(data)):\n",
    "            if data[component1-1][i] > upper_PC1 or data[component1-1][i] < lower_PC1:\n",
    "                outliers.append(i)\n",
    "            elif data[component2-1][i] > upper_PC2 or data[component2-1][i] < lower_PC2:\n",
    "                outliers.append(i)\n",
    "\n",
    "        dataframe_new = dataframe.drop(outliers)\n",
    "        dataframe_new_unlabeled = dataframe_new.drop(columns = ['Labels'])\n",
    "\n",
    "        mca = prince.MCA(\n",
    "        n_components= component2,\n",
    "        n_iter=3,\n",
    "        copy=True,\n",
    "        check_input=True,\n",
    "        engine='sklearn',\n",
    "        random_state=47\n",
    "        )\n",
    "\n",
    "        mca = mca.fit(dataframe_new_unlabeled)\n",
    "        data = mca.row_coordinates(dataframe_new_unlabeled)\n",
    "\n",
    "\n",
    "    data.insert(component2,\"Group\",dataframe[\"Labels\"])\n",
    "\n",
    "\n",
    "    colors = {label1: '#E66100', label2: '#5D3A9B'}\n",
    "    color_list = [colors[group] for group in data['Group']]\n",
    "\n",
    "    variances = mca.eigenvalues_summary[\"% of variance\"]\n",
    "\n",
    "    data.plot.scatter(x=component1-1,y=component2-1,c=color_list, grid = False,\n",
    "                      xlabel = \"Dimension \" + str(component1) + \" (\" +variances[component1-1] + \")\",\n",
    "                      ylabel = \"Dimension \" + str(component2) + \" (\" +variances[component2-1]+ \")\")\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "\n",
    "    #define patches and lines to add to legend\n",
    "    patch1 = mpatches.Patch(color='#E66100', label=\"VSD\")\n",
    "    patch2 = mpatches.Patch(color='#5D3A9B', label=\"ORD\")   \n",
    "    handles.extend([patch1, patch2])\n",
    "    plt.legend(handles=handles)\n",
    "\n",
    "\n",
    "\n",
    "def scale_column(column):\n",
    "    max = column.max()\n",
    "    min = column.min()\n",
    "\n",
    "    scaled = []\n",
    "    for value in column:\n",
    "        if value == 0:\n",
    "            scaled.append(0)\n",
    "        elif value < 0:\n",
    "            scaled.append(value/min)\n",
    "        else:  \n",
    "            scaled.append(value/max)\n",
    "\n",
    "    return scaled\n",
    "\n",
    "def adjust(value):\n",
    "    if value >= 0:\n",
    "        return value + 0.02\n",
    "    else:\n",
    "        return value - 0.02\n",
    "\n",
    "def pca_prince_biplot(dataframe ,component1 = 1, component2 = 2,remove_outliers = True,factors = 5,percentile =0.95):\n",
    "    pca = prince.PCA(\n",
    "        n_components= component2,\n",
    "        n_iter=3,\n",
    "        copy=True,\n",
    "        check_input=True,\n",
    "        engine='sklearn',\n",
    "        random_state=47\n",
    "    )\n",
    "\n",
    "    dataframe_unlabeled = dataframe.drop(columns = ['Labels'])\n",
    "    pca = pca.fit(dataframe_unlabeled)\n",
    "    \n",
    "    if remove_outliers == True:\n",
    "        data = pca.row_coordinates(dataframe_unlabeled)\n",
    "        upper_PC1 = data.quantile(0.95)[component1-1]\n",
    "        lower_PC1 = data.quantile(0.05)[component1-1]\n",
    "        upper_PC2 = data.quantile(0.95)[component2-1]\n",
    "        lower_PC2 = data.quantile(0.05)[component2-1]\n",
    "\n",
    "        outliers = []\n",
    "        for i in range(len(data)):\n",
    "            if data[component1-1][i] > upper_PC1 or data[component1-1][i] < lower_PC1:\n",
    "                outliers.append(i)\n",
    "            elif data[component2-1][i] > upper_PC2 or data[component2-1][i] < lower_PC2:\n",
    "                outliers.append(i)\n",
    "\n",
    "        dataframe_new = dataframe.drop(outliers)\n",
    "        dataframe_new_unlabeled = dataframe_new.drop(columns = ['Labels'])\n",
    "\n",
    "        pca = prince.PCA(\n",
    "        n_components= component2,\n",
    "        n_iter=3,\n",
    "        copy=True,\n",
    "        check_input=True,\n",
    "        engine='sklearn',\n",
    "        random_state=47\n",
    "        )\n",
    "        pca = pca.fit(dataframe_new_unlabeled)\n",
    "\n",
    "    contributions = pca.column_coordinates_\n",
    "    #contributions = contributions.apply(scale_column)\n",
    "    display(contributions.sort_values(by = component1-1))\n",
    "    display(contributions.sort_values(by = component2-1))\n",
    "\n",
    "    pc1_95 = contributions.quantile(percentile)[component1-1]\n",
    "    pc2_95 = contributions.quantile(percentile)[component2-1]\n",
    "    pc1_5 = contributions.quantile(1-percentile)[component1-1]\n",
    "    pc2_5 = contributions.quantile(1-percentile)[component2-1]\n",
    "\n",
    "\n",
    "    roman_numerals = {\n",
    "        1: \"I\",\n",
    "        2: \"II\",\n",
    "        3: \"III\",\n",
    "        4: \"IV\",\n",
    "        5: \"V\",\n",
    "        6: \"VI\",\n",
    "        7: \"VII\",\n",
    "        8: \"VIII\",\n",
    "        9: \"IX\",\n",
    "        10: \"X\"\n",
    "    }\n",
    "    \n",
    "    for i in range(len(contributions)):\n",
    "        label = str(int(i/factors)+1) + roman_numerals[i%factors + 1]\n",
    "        if contributions[component1-1][i] > pc1_95 or contributions[component2-1][i] > pc2_95 or contributions[component1-1][i] < pc1_5 or contributions[component2-1][i] < pc2_5:\n",
    "            \n",
    "            plt.arrow(0,0,contributions[component1-1][i],contributions[component2-1][i],color = 'r',width = 0.000005)\n",
    "            plt.text(adjust(contributions[component1-1][i]),adjust(contributions[component2-1][i]), label, color = 'g', ha = 'center', va = 'center',fontsize = 5)\n",
    "    plt.xlabel(\"PC\" + str(component1))\n",
    "    plt.ylabel(\"PC\" + str(component2))\n",
    "    plt.rcParams['figure.dpi'] = 500\n",
    "    plt.show()\n",
    "\n",
    "def pca_prince_biplot_var(dataframe ,component1 = 1, component2 = 2,remove_outliers = True,percentile =0.95):\n",
    "    pca = prince.PCA(\n",
    "        n_components= component2,\n",
    "        n_iter=3,\n",
    "        copy=True,\n",
    "        check_input=True,\n",
    "        engine='sklearn',\n",
    "        random_state=47\n",
    "    )\n",
    "\n",
    "    dataframe_unlabeled = dataframe.drop(columns = ['Labels'])\n",
    "\n",
    "    pca = pca.fit(dataframe_unlabeled)\n",
    "    \n",
    "\n",
    "    if remove_outliers == True:\n",
    "        data = pca.row_coordinates(dataframe_unlabeled)\n",
    "    \n",
    "        #need a better outlier detection method\n",
    "        upper_PC1 = data.quantile(0.95)[component1-1]\n",
    "        lower_PC1 = data.quantile(0.05)[component1-1]\n",
    "        upper_PC2 = data.quantile(0.95)[component2-1]\n",
    "        lower_PC2 = data.quantile(0.05)[component2-1]\n",
    "\n",
    "\n",
    "        outliers = []\n",
    "        for i in range(len(data)):\n",
    "            if data[component1-1][i] > upper_PC1 or data[component1-1][i] < lower_PC1:\n",
    "                outliers.append(i)\n",
    "            elif data[component2-1][i] > upper_PC2 or data[component2-1][i] < lower_PC2:\n",
    "                outliers.append(i)\n",
    "\n",
    "        \n",
    "        dataframe_new = dataframe.drop(outliers)\n",
    "        dataframe_new_unlabeled = dataframe_new.drop(columns = ['Labels'])\n",
    "\n",
    "        pca = prince.PCA(\n",
    "        n_components= component2,\n",
    "        n_iter=3,\n",
    "        copy=True,\n",
    "        check_input=True,\n",
    "        engine='sklearn',\n",
    "        random_state=47\n",
    "        )\n",
    "        pca = pca.fit(dataframe_new_unlabeled)\n",
    "\n",
    "    \n",
    "\n",
    "    contributions = pca.column_coordinates_\n",
    "    #contributions = contributions.apply(scale_column)\n",
    "    display(contributions.sort_values(by = component1-1))\n",
    "    display(contributions.sort_values(by = component2-1))\n",
    "\n",
    "    \n",
    "    pc1_95 = contributions.quantile(percentile)[component1-1]\n",
    "    pc2_95 = contributions.quantile(percentile)[component2-1]\n",
    "    pc1_5 = contributions.quantile(1-percentile)[component1-1]\n",
    "    pc2_5 = contributions.quantile(1-percentile)[component2-1]\n",
    "\n",
    "\n",
    "    roman_numerals = {\n",
    "        1: \"I\",\n",
    "        2: \"II\",\n",
    "        3: \"III\",\n",
    "        4: \"IV\",\n",
    "        5: \"V\",\n",
    "        6: \"VI\",\n",
    "        7: \"VII\",\n",
    "        8: \"VIII\",\n",
    "        9: \"IX\",\n",
    "        10: \"X\"\n",
    "    }\n",
    "    \n",
    "    for i in range(len(contributions)):\n",
    "        label = str(i+1)\n",
    "        if contributions[component1-1][i] > pc1_95 or contributions[component2-1][i] > pc2_95 or contributions[component1-1][i] < pc1_5 or contributions[component2-1][i] < pc2_5:\n",
    "            \n",
    "            plt.arrow(0,0,contributions[component1-1][i],contributions[component2-1][i],color = 'r',width = 0.000005)\n",
    "            plt.text(adjust(contributions[component1-1][i]),adjust(contributions[component2-1][i]), label, color = 'g', ha = 'center', va = 'center',fontsize = 5)\n",
    "    plt.xlabel(\"PC\" + str(component1))\n",
    "    plt.ylabel(\"PC\" + str(component2))\n",
    "    plt.rcParams['figure.dpi'] = 500\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def mca_prince_biplot(dataframe ,component1 = 1, component2 = 2,remove_outliers = True,factors = 5,percentile = 0.95):\n",
    "    mca = prince.MCA(\n",
    "        n_components= component2,\n",
    "        n_iter=3,\n",
    "        copy=True,\n",
    "        check_input=True,\n",
    "        engine='sklearn',\n",
    "        random_state=47\n",
    "    )\n",
    "\n",
    "    dataframe_unlabeled = dataframe.drop(columns = ['Labels'])\n",
    "    mca = mca.fit(dataframe_unlabeled)\n",
    "    \n",
    "\n",
    "    if remove_outliers == True:\n",
    "        data = mca.row_coordinates(dataframe_unlabeled)\n",
    "    \n",
    "        #need a better outlier detection method\n",
    "        upper_PC1 = data.quantile(.95)[component1-1]\n",
    "        lower_PC1 = data.quantile(.05)[component1-1]\n",
    "        upper_PC2 = data.quantile(.95)[component2-1]\n",
    "        lower_PC2 = data.quantile(.05)[component2-1]\n",
    "\n",
    "\n",
    "        outliers = []\n",
    "        for i in range(len(data)):\n",
    "            if data[component1-1][i] > upper_PC1 or data[component1-1][i] < lower_PC1:\n",
    "                outliers.append(i)\n",
    "            elif data[component2-1][i] > upper_PC2 or data[component2-1][i] < lower_PC2:\n",
    "                outliers.append(i)\n",
    "\n",
    "        \n",
    "        dataframe_new = dataframe.drop(outliers)\n",
    "        dataframe_new_unlabeled = dataframe_new.drop(columns = ['Labels'])\n",
    "\n",
    "        mca = prince.MCA(\n",
    "        n_components= component2,\n",
    "        n_iter=3,\n",
    "        copy=True,\n",
    "        check_input=True,\n",
    "        engine='sklearn',\n",
    "        random_state=47\n",
    "        )\n",
    "        mca = mca.fit(dataframe_new_unlabeled)\n",
    "        contributions = mca.column_coordinates(dataframe_new_unlabeled)\n",
    "    else:\n",
    "        contributions = mca.column_coordinates(dataframe_unlabeled)\n",
    "\n",
    "    display(contributions)\n",
    "    #contributions = contributions.apply(scale_column)\n",
    "    display(contributions.head())\n",
    "    \n",
    "    pc1_95 = contributions.quantile(.99)[component1-1]\n",
    "    pc2_95 = contributions.quantile(.99)[component2-1]\n",
    "    pc1_5 = contributions.quantile(.01)[component1-1]\n",
    "    pc2_5 = contributions.quantile(.01)[component2-1]\n",
    "\n",
    "\n",
    "    roman_numerals = {\n",
    "        1: \"I\",\n",
    "        2: \"II\",\n",
    "        3: \"III\",\n",
    "        4: \"IV\",\n",
    "        5: \"V\",\n",
    "        6: \"VI\",\n",
    "        7: \"VII\",\n",
    "        8: \"VIII\",\n",
    "        9: \"IX\",\n",
    "        10: \"X\"\n",
    "    }\n",
    "\n",
    "    \n",
    "\n",
    "    for i in range(len(contributions)):\n",
    "        label = str(int(i/factors)+1) + roman_numerals[i%factors + 1]\n",
    "        if contributions[component1-1][i] > pc1_95 or contributions[component2-1][i] > pc2_95 or contributions[component1-1][i] < pc1_5 or contributions[component2-1][i] < pc2_5:\n",
    "            \n",
    "            plt.arrow(0,0,contributions[component1-1][i],contributions[component2-1][i],color = 'r',width = 0.000005)\n",
    "            plt.text(adjust(contributions[component1-1][i]),adjust(contributions[component2-1][i]), label, color = 'g', ha = 'center', va = 'center',fontsize = 5)\n",
    "            \n",
    "    plt.xlabel(\"PC\" + str(component1))\n",
    "    plt.ylabel(\"PC\" + str(component2))\n",
    "    plt.rcParams['figure.dpi'] = 500\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_IX = IXfactor_conv(art_sequences[\"Sequence\"],art_sequences[\"Label\"])\n",
    "art_V = Vfactor_conv(art_sequences[\"Sequence\"],art_sequences[\"Label\"])\n",
    "art_bin = binary_conv(art_sequences[\"Sequence\"],art_sequences[\"Label\"])\n",
    "art_var = variability_conv(art_sequences[\"Sequence\"],art_sequences[\"Label\"])\n",
    "\n",
    "mamvert_IX = IXfactor_conv(mamvert_sequences[\"Sequence\"],mamvert_sequences[\"Label\"])\n",
    "mamvert_V = Vfactor_conv(mamvert_sequences[\"Sequence\"],mamvert_sequences[\"Label\"])\n",
    "mamvert_bin = binary_conv(mamvert_sequences[\"Sequence\"],mamvert_sequences[\"Label\"])\n",
    "mamvert_var = variability_conv(mamvert_sequences[\"Sequence\"],mamvert_sequences[\"Label\"])\n",
    "                               \n",
    "hexapeptide_IX = IXfactor_conv(hexapeptide_sequences[\"Sequence\"],hexapeptide_sequences[\"Classification\"])\n",
    "hexapeptide_V = Vfactor_conv(hexapeptide_sequences[\"Sequence\"],hexapeptide_sequences[\"Classification\"])\n",
    "hexapeptide_bin = binary_conv(hexapeptide_sequences[\"Sequence\"],hexapeptide_sequences[\"Classification\"])\n",
    "hexapeptide_var = variability_conv(hexapeptide_sequences[\"Sequence\"],hexapeptide_sequences[\"Classification\"])\n",
    "\n",
    "feline_IX = IXfactor_conv(feline_sequences[\"Sequence\"],feline_sequences[\"Label\"])\n",
    "feline_V = Vfactor_conv(feline_sequences[\"Sequence\"],feline_sequences[\"Label\"])\n",
    "feline_bin = binary_conv(feline_sequences[\"Sequence\"],feline_sequences[\"Label\"])\n",
    "feline_var = variability_conv(feline_sequences[\"Sequence\"],feline_sequences[\"Label\"])\n",
    "\n",
    "pca_prince_biplot(hexapeptide_V,1,2,True,5,percentile = 0.8)\n",
    "pca_prince_biplot(feline_V,1,2,False,5,percentile = 0.99)\n",
    "pca_prince_biplot(art_V,1,2,False,5,percentile = 0.8)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
